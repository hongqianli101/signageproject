<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Sign of the City</title>
    <style>
* {
    margin: 0;
    padding: 0;
    box-sizing: border-box; /* Ensures consistent box model */
}

    body {
    font-family: Arial, sans-serif;
    color: #ffffff;
    line-height: 1.6;
    margin: 0;
    padding: 0;
    font-family: Helvetica, sans-serif;
    background-color: #000000;
    position: relative; 
}

        #backgroundimagesec {
            margin: 0;
            position: relative;
            width: 100vw;
            height: 100vh;
            background-image: url('/data/coverb.png'); 
            background-size: cover; 
            background-position: center;
            background-repeat: no-repeat;
            z-index: -1;
        }

        section {
            width: 1000px;
            margin: 12px auto; 
        }

        #begin {
            height: 100vh;
            text-align: center;
            margin: 0 auto; 

            
        }

        header, section {
            padding: 10px;
        }

        h1 {
            font-size: 78px;
            margin-bottom: 4px;
            margin-top: 36%;
        }

        p {
            font-size: 20px;
        }

        h2 {
            font-size: 30px;
            margin-bottom: 8px;
            margin-top: 8px;
        }

        h3 {
            font-size: 24px;
        }

        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px 0;
        }

        #researchsite {
            width: 700px; 
            align-content: center;
            margin: 0 auto; 
        }

        #researchsite {
            width: 700px; 
            align-content: center;
            margin: 0 auto; 
        }

        #scroll {
            width: 800px;
            align-content: center;
            margin: 0 auto; 
        }


        ul {
            list-style: disc;
            padding-left: 40px;
            font-size: 18px;
        }

        figcaption {
            margin: 10px;
            font-size: 20px; 
            color: #888;
            text-align: center; 
        }

        #playButton {
    display: block;
    margin: 200px auto 200px auto; /* Centers the button horizontally and adds top & bottom margins */
    padding: 15px 40px; /* Balanced padding for a readable button size */
    font-size: 24px; /* Reasonable font size for readability */
    color: white; /* Button text color */
    background-color: transparent; /* Optional: Transparent background for a minimalistic style */
    border: 2px solid #ffffff; /* Sets border width, style, and color */
    border-radius: 12px; /* Rounded corners */
    cursor: pointer; /* Pointer cursor on hover */
    font-weight: 500; /* Medium weight for button text */
    letter-spacing: 2px; /* Adds spacing between letters */
    transition: background-color 0.3s ease, color 0.3s ease, box-shadow 0.3s ease; /* Smooth hover effects */
}


        #playButton:hover {
            background-color: #515151;
        }

    </style>
</head>

<body>
    <section id="backgroundimagesec">
    </section>

    <!-- <section id="begin">
        <h1>The Sign of the City</h1>
        <h2>——Decoding Urban Stories Through AI and Signage</h2>
        <h3>Hongqian Li</h3>
    </section> -->

    <section id="background">
        <h2>Background</h2>
        <h3>The development of urban visual information study</h3>
        <img src="/data/development.png" alt="The development of urban visual information study">
        <figcaption>The development of urban visual information study</figcaption>
        <p>
            The tradition of incorporating visual information runs through the entire history of modern urban studies. 
            In the late 1900s, Camilo Sitte and Ebenezer Howard started to study the sensory experience of citizens, 
            emphasizing the shape and proportion of beauty in the public space. In the 1970s, Kevin Lynch started to 
            study structure and human perceptions in the city. As they lay the foundation of many urban visual information 
            studies, most of these are more focused on the physical aspects like shape, proportion, and human perceptions 
            but do not much extend beyond these traditional dimensions to explore other aspects such as cultural, economic, 
            and political aspects. With the development of AI, which could potentially open new opportunities in urban visual 
            study, how can we utilize it to build up on the previous studies?
        </p>
    </section>

    <section id="image-of-the-city">
        <h3>Adding more to the Image of the City?</h3>
        <img src="/data/imageofcity.gif" alt="Adding more to the Image of the City">
        <figcaption>Adding more to the Image of the City</figcaption>
        <p>
            In the book <i>The Image of the City</i> by Kevin Lynch, he stated that a well-designed city incorporating 5 elements 
            - paths, edges, districts, nodes, and landmarks - would obviate the need for additional signages, as the urban 
            structure itself would inherently guide and inform. As long as people need signage, the image of the city fails...
        </p>
        <p>
            However in modern cities, are there any cities with no signs? As one of the few elements in urban street views 
            containing words and texts, signs offer a unique opportunity to glean insights beyond physical attributes, extending 
            into more cultural, commercial, and political aspects. Therefore, this thesis seeks to explore a new way of urban visual 
            information study, by taking what previous research overlooked and what Kevin Lynch considers a "failure" - signage - 
            as an advantage, and leveraging new AI technology, to add more to the images of the city.
        </p>
    </section>

    <section id="research-questions">
        <h2>Research Questions</h2>
        <ul>
            <li>What AI technologies can help extract more information from urban images?</li>
            <li>What do signs tell us about the city?</li>
            <li>
                What types of information signs can add to our understanding of the city
                (Cultural, Financial, Temporary, Informal, Lexicon...)?
            </li>
        </ul>
    </section>

    <section id="methodology">
        <h2>Methodology</h2>
        <img src="/data/methodology.gif" alt="Research methodology">
        <figcaption>Research Methodology</figcaption>
        <p>
            The research methodology consists of two steps: first, web-scraping to gather Street View images from Google Maps of the 
            designated research site; second, analyzing these images using Deep Learning algorithms to classify the signs. After 
            classification, the sign areas are extracted for further analysis. Optical Character Recognition (OCR) algorithms are then 
            employed to decipher the content and language displayed in the signs.
        </p>
    </section>

    <section id="studyfield">
        <h2>Research Site</h2>
        <img id="researchsite" src="/data/researchsite.png" alt="Research site">
        <figcaption>Research Site</figcaption>
        <p>
            For the research, New York City was chosen as the primary site due to its rich diversity and urban complexity. To ensure 
            representative sampling, the project identified central points within each borough as starting locations. Using a Python 
            script to calculate the shortest path, a route was generated that traverses 46 New York Neighborhood Tabulation Areas (NTAs),
             capturing a wide range of socio-economic characteristics across the city.
        </p>
    </section>

    <section id="findings">
        <h2>Findings</h2>
        <img src="/data/index.png" alt="Signs type & language in NYC">
        <figcaption>Signs type & language in NYC</figcaption>
        <p>
            19 signage types were identified in New York City and can be grouped into three main categories. The first group is street signs, 
            which include Don't Block signs, Do Not Enter signs, and All Traffic signs, etc. The second group consists of business-related 
            signs, including Shop signs, For rent signs, Promotion signs, etc. The third category is public infrastructure signs, including 
            Bus stop signs, Scaffolding signs, Subway signs, etc. 7 signage languages were identified, including 6 non-English languages: 
            Spanish, Chinese, French, Italian, Korean, and Russian.
        </p>
        <img id="scroll" src="/data/result-long.png" alt="A Scroll of NYC signs">
        <figcaption>Data Visualization Overview</figcaption>
        <p>
            Signs tell us about different neighborhoods' financial, cultural, and lexical layers... In Midtown and Flushing, diverse shop 
            signs point to vibrant local commercial hubs. Lease signs, particularly prominent in Midtown South, indicate ongoing rental 
            activity. Sign language reflects the ethnic composition of each area, with Chinese signage prevalent in Flushing, Italian in 
            Ocean Hill, and Spanish in Woodhaven, which notably also features a significant number of Korean signs. Sign content reveals 
            varied local lexicons, with phrases like "best" commonly seen in Flatbush and Brownsville, and "lucky" prevalent in Chinatown...
        </p>
    </section>
    <button id="playButton" onclick="location.href='application.html'">PLAY THE APPLICATION</button>

</body>
</html>